# False Political Claim Detection Challenge  

This repository contains my participation in a **Natural Language Processing (NLP) and Machine Learning competition** based on a real-world problem: predicting whether a **political claim** is **true or false**.  

The task simulates the role of a fact-checker who needs to assess the truthfulness of statements made by politicians or public figures.  

## ğŸ“Œ Problem Statement  
Given a dataset of political claims, the goal is to **build a classifier that determines whether a claim is false or true**.  

As a fact-checker, the key question is:  
ğŸ‘‰ *Is this political claim false? Why or why not?*  

This decision is made by analyzing historical claims and their context using NLP and ML techniques.  

## ğŸ“Š Evaluation Metric  
The competition is evaluated using **accuracy and classification metrics**, as it is a **binary classification problem** (True / False).  

- **Precision (p):** Ratio of true positives to all predicted positives.  
- **Recall (r):** Ratio of true positives to all actual positives.  
- **F1-Score:** Harmonic mean of precision and recall, useful for imbalanced classes.  

## ğŸ“‚ Dataset Description  

The dataset consists of political claims with metadata about the speaker, topic, and context.  

**Files provided:**  
- `train.csv` â†’ Training data with features + target (`label`).  
- `test.csv` â†’ Test data (without target).  
- Metadata includes speaker, occupation, party affiliation, and geographic context.  

**Main Features:**  
- `id` â†’ Unique identifier of the claim  
- `label` â†’ **Target variable** (0 = True, 1 = False)  
- `statement` â†’ Text of the claim  
- `subject` â†’ Topic of the claim  
- `speaker` â†’ Person making the claim  
- `speaker_job` â†’ Occupation of the speaker  
- `state_info` â†’ Geographic context  
- `party_affiliation` â†’ Political party of the speaker  

## ğŸ—‚ï¸ Project Structure  

The workflow has been divided into several Jupyter notebooks:  

1. **`1.1_Carga_limpieza_datos.ipynb`** â†’ Data loading & initial cleaning  
2. **`1.2_Carga_limpieza_datos-LLM_Dataset_Completation.ipynb`** â†’ Dataset completion using LLM techniques  
3. **`1.3_Carga_limpieza_datos-Transformers.ipynb`** â†’ Text preprocessing with Transformers  
4. **`1.4_Carga_limpieza_datos-Dictionary-n-Onehot.ipynb`** â†’ Encoding categorical variables  
5. **`2_Visualizacion_de_los_datos.ipynb`** â†’ Exploratory Data Analysis (EDA)  
6. **`3_Model_Evaluation.ipynb`** â†’ Model evaluation strategy & metrics  
7. **`4_Seleccion_caracteristicas_y_preprocesado.ipynb`** â†’ Feature selection & preprocessing  
8. **`5_Entrenamiento_y_evaluacion_modelos_TF_IDF.ipynb`** â†’ Model training & evaluation using TF-IDF features  
9. **`6_Entrenamiento_y_evaluacion_modelos_word2Vec.ipynb`** â†’ Word2Vec-based models  
10. **`7_Entrenamiento_y_evaluacion_modelos_Hugging.ipynb`** â†’ Hugging Face Transformers models  
11. **`8_Entrenamiento_y_evaluacion_modelos_Selectivo.ipynb`** â†’ Selective model training experiments  
12. **`9_VisualizaciÃ³n_de_resultados.ipynb`** â†’ Visualization of results & performance metrics  
